{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-07-17T08:47:14.032344Z",
     "iopub.status.busy": "2021-07-17T08:47:14.03186Z",
     "iopub.status.idle": "2021-07-17T08:47:14.039862Z",
     "shell.execute_reply": "2021-07-17T08:47:14.038621Z",
     "shell.execute_reply.started": "2021-07-17T08:47:14.032298Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-17T08:47:14.042082Z",
     "iopub.status.busy": "2021-07-17T08:47:14.041648Z",
     "iopub.status.idle": "2021-07-17T08:47:16.360314Z",
     "shell.execute_reply": "2021-07-17T08:47:16.359109Z",
     "shell.execute_reply.started": "2021-07-17T08:47:14.04203Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/remekkinas/lstm-seq2seq-encoder-decoder#SIMPLE-NN-MODEL\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, ConvLSTM2D, Dropout\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-17T08:47:16.362202Z",
     "iopub.status.busy": "2021-07-17T08:47:16.36194Z",
     "iopub.status.idle": "2021-07-17T08:47:16.36735Z",
     "shell.execute_reply": "2021-07-17T08:47:16.366318Z",
     "shell.execute_reply.started": "2021-07-17T08:47:16.362176Z"
    }
   },
   "outputs": [],
   "source": [
    "n_steps = 8 # we use 12h window\n",
    "n_lookup = 1 # predict series of 4 values in time t1, t2, t3, t4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-17T08:47:16.369682Z",
     "iopub.status.busy": "2021-07-17T08:47:16.369294Z",
     "iopub.status.idle": "2021-07-17T08:47:16.428648Z",
     "shell.execute_reply": "2021-07-17T08:47:16.427646Z",
     "shell.execute_reply.started": "2021-07-17T08:47:16.369641Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2247, 9)\n",
      "(2247, 4)\n",
      "(2255, 8)\n",
      "(9366, 9)\n"
     ]
    }
   ],
   "source": [
    "# df_train = pd.read_csv(\"../input/tabular-playground-series-jul-2021/train.csv\")\n",
    "# df_test = pd.read_csv(\"../input/tabular-playground-series-jul-2021/test.csv\")\n",
    "# df_sub = pd.read_csv(\"../input/tabular-playground-series-jul-2021/sample_submission.csv\")\n",
    "\n",
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_test = pd.read_csv(\"test.csv\")\n",
    "df_sub = pd.read_csv(\"sample_submission.csv\")\n",
    "\n",
    "print(df_test.shape)\n",
    "print(df_sub.shape)\n",
    "\n",
    "features = ['deg_C', 'relative_humidity', 'absolute_humidity', 'sensor_1', 'sensor_2', 'sensor_3', 'sensor_4', 'sensor_5']\n",
    "targets = ['target_carbon_monoxide', 'target_benzene', 'target_nitrogen_oxides']\n",
    "targets_values = np.log1p(df_train[targets]).values\n",
    "\n",
    "\n",
    "df_test = pd.concat([df_train[len(df_train)-n_steps-1:len(df_train)-1].drop(targets , axis = 1), df_test])\n",
    "\n",
    "df_all = pd.concat([df_train.drop(targets , axis = 1), df_test])\n",
    "\n",
    "df_all['date_time'] = pd.to_datetime(df_all['date_time'])\n",
    "\n",
    "\n",
    "df_train.set_index('date_time', inplace=True)\n",
    "df_test.set_index('date_time', inplace=True)\n",
    "print(df_test.shape)\n",
    "print(df_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-17T08:47:16.430753Z",
     "iopub.status.busy": "2021-07-17T08:47:16.43033Z",
     "iopub.status.idle": "2021-07-17T08:47:16.437249Z",
     "shell.execute_reply": "2021-07-17T08:47:16.435891Z",
     "shell.execute_reply.started": "2021-07-17T08:47:16.430712Z"
    }
   },
   "outputs": [],
   "source": [
    "def cycle_sin_cos_coder(data, cols):\n",
    "    for col in cols:\n",
    "        data[col + '_s'] = np.sin(2 * np.pi * data[col]/data[col].max())\n",
    "        data[col + '_c'] = np.cos(2 * np.pi * data[col]/data[col].max())\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-17T08:47:16.438911Z",
     "iopub.status.busy": "2021-07-17T08:47:16.438606Z",
     "iopub.status.idle": "2021-07-17T08:47:16.477418Z",
     "shell.execute_reply": "2021-07-17T08:47:16.476186Z",
     "shell.execute_reply.started": "2021-07-17T08:47:16.438879Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9366, 14)\n"
     ]
    }
   ],
   "source": [
    "df_all['month'] = df_all['date_time'].dt.month\n",
    "df_all['day'] = df_all['date_time'].dt.day\n",
    "df_all['hour'] = df_all['date_time'].dt.hour\n",
    "\n",
    "df_all = cycle_sin_cos_coder(df_all, ['month','day','hour'])\n",
    "df_all.drop(['month','day','hour'], axis=1, inplace=True)\n",
    "df_all.set_index('date_time', inplace=True)\n",
    "\n",
    "print(df_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-17T08:47:16.479198Z",
     "iopub.status.busy": "2021-07-17T08:47:16.478902Z",
     "iopub.status.idle": "2021-07-17T08:47:16.491157Z",
     "shell.execute_reply": "2021-07-17T08:47:16.489896Z",
     "shell.execute_reply.started": "2021-07-17T08:47:16.479169Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train = df_all[:len(df_train)]\n",
    "\n",
    "df_train [targets] = targets_values\n",
    "df_test = df_all[len(df_train):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-17T08:47:16.493343Z",
     "iopub.status.busy": "2021-07-17T08:47:16.492918Z",
     "iopub.status.idle": "2021-07-17T08:47:16.50561Z",
     "shell.execute_reply": "2021-07-17T08:47:16.504536Z",
     "shell.execute_reply.started": "2021-07-17T08:47:16.493298Z"
    }
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(df_train, shuffle = False, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-17T08:47:16.510188Z",
     "iopub.status.busy": "2021-07-17T08:47:16.50968Z",
     "iopub.status.idle": "2021-07-17T08:47:16.530349Z",
     "shell.execute_reply": "2021-07-17T08:47:16.529435Z",
     "shell.execute_reply.started": "2021-07-17T08:47:16.510114Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in train[features].columns:\n",
    "    scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "    \n",
    "    s_train = scaler.fit_transform(train[i].values.reshape(-1,1))\n",
    "    s_test = scaler.transform(test[i].values.reshape(-1,1))\n",
    "    s_df_test = scaler.transform(df_test[i].values.reshape(-1,1))\n",
    "    \n",
    "    s_train = np.reshape(s_train,len(s_train))\n",
    "    s_test = np.reshape(s_test,len(s_test))\n",
    "    s_df_test = np.reshape(s_df_test,len(s_df_test))\n",
    "\n",
    "    train[i] = s_train\n",
    "    test[i] = s_test\n",
    "    df_test[i] = s_df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-17T08:47:16.532636Z",
     "iopub.status.busy": "2021-07-17T08:47:16.532338Z",
     "iopub.status.idle": "2021-07-17T08:47:16.540009Z",
     "shell.execute_reply": "2021-07-17T08:47:16.538864Z",
     "shell.execute_reply.started": "2021-07-17T08:47:16.532607Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_sequences(Xsequences, ysequences, n_steps = 6, n_out = 1):\n",
    "    X, y = list(), list()\n",
    "\n",
    "    for i in range(len(Xsequences)):\n",
    "        end_index = i + n_steps\n",
    "        out_end_index = end_index + n_out\n",
    "        \n",
    "        if out_end_index > len(Xsequences):\n",
    "            break\n",
    "        \n",
    "        seq_x = Xsequences.iloc[i : end_index, :] \n",
    "        if isinstance(ysequences, pd.core.series.Series):\n",
    "            seq_y = ysequences.iloc[end_index : out_end_index]\n",
    "            y.append(seq_y)\n",
    "\n",
    "        X.append(seq_x)\n",
    "        \n",
    "    return array(X), array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-17T08:47:16.541286Z",
     "iopub.status.busy": "2021-07-17T08:47:16.541012Z",
     "iopub.status.idle": "2021-07-17T08:47:22.677993Z",
     "shell.execute_reply": "2021-07-17T08:47:22.676869Z",
     "shell.execute_reply.started": "2021-07-17T08:47:16.54125Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5680, 8, 14) (5680, 1)\n",
      "(1415, 8, 14) (1415, 1)\n"
     ]
    }
   ],
   "source": [
    "Xtrain_seq_tcm, ytrain_seq_tcm = split_sequences(train.drop(targets, axis = 1), train['target_carbon_monoxide'], n_steps, n_lookup)\n",
    "Xtest_seq_tcm, ytest_seq_tcm = split_sequences(test.drop(targets, axis = 1), test['target_carbon_monoxide'], n_steps, n_lookup)\n",
    "\n",
    "Xtrain_seq_tb, ytrain_seq_tb = split_sequences(train.drop(targets, axis = 1), train['target_benzene'], n_steps, n_lookup)\n",
    "Xtest_seq_tb, ytest_seq_tb = split_sequences(test.drop(targets, axis = 1), test['target_benzene'], n_steps, n_lookup)\n",
    "\n",
    "Xtrain_seq_tno, ytrain_seq_tno = split_sequences(train.drop(targets, axis = 1), train['target_nitrogen_oxides'], n_steps, n_lookup)\n",
    "Xtest_seq_tno, ytest_seq_tno = split_sequences(test.drop(targets, axis = 1), test['target_nitrogen_oxides'], n_steps, n_lookup)\n",
    "\n",
    "n_features = Xtrain_seq_tcm.shape[2]\n",
    "\n",
    "print(Xtrain_seq_tcm.shape, ytrain_seq_tcm.shape)\n",
    "print(Xtest_seq_tcm.shape, ytest_seq_tcm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-17T08:47:22.679907Z",
     "iopub.status.busy": "2021-07-17T08:47:22.679504Z",
     "iopub.status.idle": "2021-07-17T08:47:22.96739Z",
     "shell.execute_reply": "2021-07-17T08:47:22.966334Z",
     "shell.execute_reply.started": "2021-07-17T08:47:22.679862Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.66831683 -0.58092848 -0.79686725 -0.61577008 -0.52286481 -0.38872892 -0.64293278 -0.56189824 -0.          1.         -0.          1.         -0.94226092 -0.33487961]\n",
      " [-0.68316832 -0.4880803  -0.80053534 -0.50626382 -0.35242373 -0.39942411 -0.68367995 -0.4384013  -0.          1.         -0.          1.         -0.99766877 -0.06824241]\n",
      " [-0.77722772 -0.42032622 -0.80410429 -0.62092852 -0.45511261 -0.37345008 -0.72620611 -0.51893534 -0.          1.         -0.          1.         -0.97908409  0.20345601]\n",
      " [-0.83168317 -0.36260979 -0.81937147 -0.56904937 -0.52847963 -0.23970147 -0.69316786 -0.47939578 -0.          1.         -0.          1.         -0.88788522  0.46006504]\n",
      " [-0.82673267 -0.42032622 -0.82799643 -0.50626382 -0.44201135 -0.35405771 -0.69833538 -0.44131114 -0.          1.         -0.          1.         -0.73083596  0.68255314]\n",
      " [-0.83168317 -0.3902133  -0.83840587 -0.47354458 -0.46846341 -0.2616795  -0.69503156 -0.44738756 -0.          1.         -0.          1.         -0.51958395  0.8544194 ]\n",
      " [-0.80693069 -0.35508156 -0.78447507 -0.44156227 -0.49678707 -0.36710348 -0.71510865 -0.22855064 -0.          1.         -0.          1.         -0.26979677  0.96291729]\n",
      " [-0.88613861 -0.20200753 -0.80678101 -0.57656595 -0.59086655 -0.31233472 -0.6915583  -0.18815525 -0.          1.         -0.          1.         -0.          1.        ]]\n",
      "(2247, 8, 14)\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True, linewidth=255)\n",
    "\n",
    "Xtest_sub, _ = split_sequences(df_test, [], n_steps, n_lookup)\n",
    "print(Xtest_sub[0])\n",
    "print(Xtest_sub.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-17T08:47:22.96894Z",
     "iopub.status.busy": "2021-07-17T08:47:22.968634Z",
     "iopub.status.idle": "2021-07-17T08:47:22.979829Z",
     "shell.execute_reply": "2021-07-17T08:47:22.978648Z",
     "shell.execute_reply.started": "2021-07-17T08:47:22.968903Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X0\n",
      " [[-0.63366337 -0.06900878 -0.4604937   0.06366986 -0.09688689 -0.13897867  0.00800542 -0.11361205  1.          0.          0.89780454 -0.44039415 -0.97908409  0.20345601]\n",
      " [-0.62871287 -0.08657465 -0.49251512 -0.09565217 -0.34593549  0.02732562 -0.24012029 -0.35538534  1.          0.          0.89780454 -0.44039415 -0.88788522  0.46006504]\n",
      " [-0.65841584  0.18695107 -0.46802816 -0.01783346 -0.29427912 -0.13404243 -0.12474057 -0.26458128  1.          0.          0.89780454 -0.44039415 -0.73083596  0.68255314]\n",
      " [-0.73762376  0.3425345  -0.43184297 -0.03389831 -0.29502776 -0.08385732 -0.16675844 -0.13945826  1.          0.          0.89780454 -0.44039415 -0.51958395  0.8544194 ]\n",
      " [-0.69306931  0.25721455 -0.42976108 -0.10611643 -0.39023021  0.00781571 -0.26926172 -0.2515726   1.          0.          0.89780454 -0.44039415 -0.26979677  0.96291729]\n",
      " [-0.72772277  0.20200753 -0.43372658 -0.18142962 -0.58387922  0.28553799 -0.22936168 -0.4083615   1.          0.          0.89780454 -0.44039415 -0.          1.        ]\n",
      " [-0.75247525  0.17440402 -0.45801527 -0.14708917 -0.61906544  0.37250984 -0.27137956 -0.56189824  1.          0.          0.79077574 -0.61210598  0.          1.        ]\n",
      " [-0.77227723  0.20702635 -0.44820065 -0.23964628 -0.66598041  0.39589822 -0.31653183 -0.60828448  1.          0.          0.79077574 -0.61210598  0.26979677  0.96291729]]\n",
      "y0\n",
      " [0.64185389] \n",
      "\n",
      "\n",
      "X1\n",
      " [[-0.62871287 -0.08657465 -0.49251512 -0.09565217 -0.34593549  0.02732562 -0.24012029 -0.35538534  1.          0.          0.89780454 -0.44039415 -0.88788522  0.46006504]\n",
      " [-0.65841584  0.18695107 -0.46802816 -0.01783346 -0.29427912 -0.13404243 -0.12474057 -0.26458128  1.          0.          0.89780454 -0.44039415 -0.73083596  0.68255314]\n",
      " [-0.73762376  0.3425345  -0.43184297 -0.03389831 -0.29502776 -0.08385732 -0.16675844 -0.13945826  1.          0.          0.89780454 -0.44039415 -0.51958395  0.8544194 ]\n",
      " [-0.69306931  0.25721455 -0.42976108 -0.10611643 -0.39023021  0.00781571 -0.26926172 -0.2515726   1.          0.          0.89780454 -0.44039415 -0.26979677  0.96291729]\n",
      " [-0.72772277  0.20200753 -0.43372658 -0.18142962 -0.58387922  0.28553799 -0.22936168 -0.4083615   1.          0.          0.89780454 -0.44039415 -0.          1.        ]\n",
      " [-0.75247525  0.17440402 -0.45801527 -0.14708917 -0.61906544  0.37250984 -0.27137956 -0.56189824  1.          0.          0.79077574 -0.61210598  0.          1.        ]\n",
      " [-0.77227723  0.20702635 -0.44820065 -0.23964628 -0.66598041  0.39589822 -0.31653183 -0.60828448  1.          0.          0.79077574 -0.61210598  0.26979677  0.96291729]\n",
      " [-0.78217822  0.35006274 -0.45355408 -0.27177598 -0.70191528  0.5128401  -0.44148418 -0.65809406  1.          0.          0.79077574 -0.61210598  0.51958395  0.8544194 ]]\n",
      "y1\n",
      " [0.47000363] \n",
      "\n",
      "\n",
      "X2\n",
      " [[-0.65841584  0.18695107 -0.46802816 -0.01783346 -0.29427912 -0.13404243 -0.12474057 -0.26458128  1.          0.          0.89780454 -0.44039415 -0.73083596  0.68255314]\n",
      " [-0.73762376  0.3425345  -0.43184297 -0.03389831 -0.29502776 -0.08385732 -0.16675844 -0.13945826  1.          0.          0.89780454 -0.44039415 -0.51958395  0.8544194 ]\n",
      " [-0.69306931  0.25721455 -0.42976108 -0.10611643 -0.39023021  0.00781571 -0.26926172 -0.2515726   1.          0.          0.89780454 -0.44039415 -0.26979677  0.96291729]\n",
      " [-0.72772277  0.20200753 -0.43372658 -0.18142962 -0.58387922  0.28553799 -0.22936168 -0.4083615   1.          0.          0.89780454 -0.44039415 -0.          1.        ]\n",
      " [-0.75247525  0.17440402 -0.45801527 -0.14708917 -0.61906544  0.37250984 -0.27137956 -0.56189824  1.          0.          0.79077574 -0.61210598  0.          1.        ]\n",
      " [-0.77227723  0.20702635 -0.44820065 -0.23964628 -0.66598041  0.39589822 -0.31653183 -0.60828448  1.          0.          0.79077574 -0.61210598  0.26979677  0.96291729]\n",
      " [-0.78217822  0.35006274 -0.45355408 -0.27177598 -0.70191528  0.5128401  -0.44148418 -0.65809406  1.          0.          0.79077574 -0.61210598  0.51958395  0.8544194 ]\n",
      " [-0.76237624  0.27227102 -0.46654109 -0.46249079 -0.80323164  0.72392314 -0.49536194 -0.80033378  1.          0.          0.79077574 -0.61210598  0.73083596  0.68255314]]\n",
      "y2\n",
      " [0.53062825] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True, linewidth=255)\n",
    "\n",
    "num_seq_show = 3\n",
    "\n",
    "for i in range(num_seq_show):\n",
    "    print(f'X{i}\\n {Xtrain_seq_tcm[i]}')\n",
    "    print(f'y{i}\\n {ytrain_seq_tcm[i]} \\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-17T08:47:22.981982Z",
     "iopub.status.busy": "2021-07-17T08:47:22.981584Z",
     "iopub.status.idle": "2021-07-17T08:47:22.99348Z",
     "shell.execute_reply": "2021-07-17T08:47:22.992302Z",
     "shell.execute_reply.started": "2021-07-17T08:47:22.981949Z"
    }
   },
   "outputs": [],
   "source": [
    "def rmsle(y_true, y_pred):\n",
    "    msle = tf.keras.losses.MeanSquaredLogarithmicError()\n",
    "    return K.sqrt(msle(y_true, y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-17T08:47:22.995354Z",
     "iopub.status.busy": "2021-07-17T08:47:22.995064Z",
     "iopub.status.idle": "2021-07-17T08:47:23.507782Z",
     "shell.execute_reply": "2021-07-17T08:47:23.506705Z",
     "shell.execute_reply.started": "2021-07-17T08:47:22.995327Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-22 21:04:19.421315: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               46000     \n",
      "_________________________________________________________________\n",
      "repeat_vector (RepeatVector) (None, 1, 100)            0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 1, 100)            80400     \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 1, 1)              101       \n",
      "=================================================================\n",
      "Total params: 126,501\n",
      "Trainable params: 126,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# A. LSTM -> Encoder-Decoder -> LSTM -> DenseÂ¶\n",
    "model_tcm = Sequential()\n",
    "model_tcm.add(LSTM(100, activation='tanh', input_shape=(n_steps, n_features)))\n",
    "model_tcm.add(RepeatVector(n_lookup))\n",
    "model_tcm.add(LSTM(100, activation='tanh', return_sequences=True))\n",
    "model_tcm.add(TimeDistributed(Dense(1)))\n",
    "model_tcm.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.02), loss= rmsle)\n",
    "\n",
    "model_tcm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-17T08:47:23.509446Z",
     "iopub.status.busy": "2021-07-17T08:47:23.50915Z",
     "iopub.status.idle": "2021-07-17T08:47:23.623034Z",
     "shell.execute_reply": "2021-07-17T08:47:23.621903Z",
     "shell.execute_reply.started": "2021-07-17T08:47:23.509415Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model_tcm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-17T08:47:23.625955Z",
     "iopub.status.busy": "2021-07-17T08:47:23.624863Z",
     "iopub.status.idle": "2021-07-17T08:47:23.632777Z",
     "shell.execute_reply": "2021-07-17T08:47:23.631634Z",
     "shell.execute_reply.started": "2021-07-17T08:47:23.625915Z"
    }
   },
   "outputs": [],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(patience=10, verbose=0, min_delta=0.001, monitor='val_loss', mode='auto', restore_best_weights=True)\n",
    "red_lr = tf.keras.callbacks.LearningRateScheduler(lambda x: 1e-3 * 0.90 ** x)\n",
    "\n",
    "def plot_model_learning(history):\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-17T08:47:23.63482Z",
     "iopub.status.busy": "2021-07-17T08:47:23.634385Z",
     "iopub.status.idle": "2021-07-17T08:57:55.655423Z",
     "shell.execute_reply": "2021-07-17T08:57:55.654436Z",
     "shell.execute_reply.started": "2021-07-17T08:47:23.634757Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b053e60b7cc94e578785a20a86dd6b60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-22 21:04:20.026871: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    }
   ],
   "source": [
    "N_SAMPLE = 20\n",
    "yhat_tcm = np.zeros((Xtest_sub.shape[0],1))\n",
    "\n",
    "for samples in tqdm(range(N_SAMPLE)):\n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    model_tcm.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.02), loss= rmsle)\n",
    "    history_tcm = model_tcm.fit(Xtrain_seq_tcm, ytrain_seq_tcm, \n",
    "                                validation_data = (Xtest_seq_tcm, ytest_seq_tcm), \n",
    "                                epochs=100, \n",
    "                                verbose = 0,\n",
    "                                batch_size = 16, \n",
    "                                callbacks=[es, red_lr])\n",
    "    \n",
    "  \n",
    "    yhat_tcm += np.expm1(model_tcm.predict(Xtest_sub)).reshape(-1,1)\n",
    "\n",
    "yhat_tcm = yhat_tcm / N_SAMPLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-17T08:57:55.657119Z",
     "iopub.status.busy": "2021-07-17T08:57:55.656858Z",
     "iopub.status.idle": "2021-07-17T08:57:55.889189Z",
     "shell.execute_reply": "2021-07-17T08:57:55.887534Z",
     "shell.execute_reply.started": "2021-07-17T08:57:55.657093Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_lst_m2d (ConvLSTM2D)    (None, 1, 1, 64)          40192     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "repeat_vector (RepeatVector) (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 1, 200)            212000    \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 1, 100)            20100     \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 1, 1)              101       \n",
      "=================================================================\n",
      "Total params: 272,393\n",
      "Trainable params: 272,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# B. ConvLSTM2D -> Encoder-Decoder -> LSTM -> Dense\n",
    "n_sub_steps = 4\n",
    "n_length = 2\n",
    "\n",
    "model_tb = Sequential()\n",
    "model_tb.add(ConvLSTM2D(64, (1,2), activation='relu', input_shape=(n_sub_steps, 1, n_length, n_features)))\n",
    "model_tb.add(Flatten())\n",
    "model_tb.add(RepeatVector(n_lookup))\n",
    "model_tb.add(LSTM(200, activation='relu', return_sequences=True))\n",
    "model_tb.add(TimeDistributed(Dense(100, activation='relu')))\n",
    "model_tb.add(TimeDistributed(Dense(1)))\n",
    "\n",
    "model_tb.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "model_tb.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-17T08:57:55.890572Z",
     "iopub.status.busy": "2021-07-17T08:57:55.890308Z",
     "iopub.status.idle": "2021-07-17T08:57:56.090336Z",
     "shell.execute_reply": "2021-07-17T08:57:56.089182Z",
     "shell.execute_reply.started": "2021-07-17T08:57:55.890545Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model_tb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-17T08:57:56.092319Z",
     "iopub.status.busy": "2021-07-17T08:57:56.092025Z",
     "iopub.status.idle": "2021-07-17T08:57:56.097729Z",
     "shell.execute_reply": "2021-07-17T08:57:56.096846Z",
     "shell.execute_reply.started": "2021-07-17T08:57:56.092288Z"
    }
   },
   "outputs": [],
   "source": [
    "Xtrain_seq_tb = Xtrain_seq_tb.reshape((Xtrain_seq_tb.shape[0], n_sub_steps, 1, n_length, n_features))\n",
    "Xtest_seq_tb = Xtest_seq_tb.reshape((Xtest_seq_tb.shape[0], n_sub_steps , 1, n_length, n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-17T08:57:56.099424Z",
     "iopub.status.busy": "2021-07-17T08:57:56.099145Z",
     "iopub.status.idle": "2021-07-17T09:07:21.855951Z",
     "shell.execute_reply": "2021-07-17T09:07:21.854869Z",
     "shell.execute_reply.started": "2021-07-17T08:57:56.099397Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b51f43031434b0b8474d67764c98c0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N_SAMPLE = 20\n",
    "yhat_tb = np.zeros((Xtest_sub.shape[0],1))\n",
    "\n",
    "for samples in tqdm(range(N_SAMPLE)):\n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    model_tb.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.02), loss= rmsle)\n",
    "    history_tb = model_tb.fit(Xtrain_seq_tb, ytrain_seq_tb, \n",
    "                          validation_data = (Xtest_seq_tb, ytest_seq_tb), \n",
    "                          epochs=100,  \n",
    "                          batch_size = 16, \n",
    "                          verbose = 0, \n",
    "                          callbacks=[es, red_lr])\n",
    "  \n",
    "    yhat_tb += np.expm1(model_tb.predict(Xtest_sub.reshape(Xtest_sub.shape[0], n_sub_steps, 1, n_length, n_features))).reshape(-1,1)\n",
    "\n",
    "yhat_tb = yhat_tb / N_SAMPLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-17T09:07:21.858286Z",
     "iopub.status.busy": "2021-07-17T09:07:21.857732Z",
     "iopub.status.idle": "2021-07-17T09:07:22.017944Z",
     "shell.execute_reply": "2021-07-17T09:07:22.016902Z",
     "shell.execute_reply.started": "2021-07-17T09:07:21.858235Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 6, 64)             2752      \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 4, 64)             12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 2, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "repeat_vector (RepeatVector) (None, 1, 128)            0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 1, 100)            91600     \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 1, 64)             6464      \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 1, 1)              65        \n",
      "=================================================================\n",
      "Total params: 113,233\n",
      "Trainable params: 113,233\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# CONV1D -> Encoder-Decoder -> LSTM -> Dense\n",
    "model_tno = Sequential()\n",
    "model_tno.add(Conv1D(64, 3, activation='relu', input_shape=(n_steps, n_features)))\n",
    "model_tno.add(Conv1D(64, 3, activation='relu'))\n",
    "model_tno.add(MaxPooling1D())\n",
    "model_tno.add(Flatten())\n",
    "model_tno.add(RepeatVector(n_lookup))\n",
    "model_tno.add(LSTM(100, activation='relu', return_sequences=True))\n",
    "model_tno.add(TimeDistributed(Dense(64, activation='relu')))\n",
    "model_tno.add(TimeDistributed(Dense(1)))\n",
    "\n",
    "model_tno.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "model_tno.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-17T09:07:22.019503Z",
     "iopub.status.busy": "2021-07-17T09:07:22.019209Z",
     "iopub.status.idle": "2021-07-17T09:07:22.291427Z",
     "shell.execute_reply": "2021-07-17T09:07:22.290592Z",
     "shell.execute_reply.started": "2021-07-17T09:07:22.019472Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model_tno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-17T09:07:22.293697Z",
     "iopub.status.busy": "2021-07-17T09:07:22.293182Z",
     "iopub.status.idle": "2021-07-17T09:12:25.469533Z",
     "shell.execute_reply": "2021-07-17T09:12:25.468585Z",
     "shell.execute_reply.started": "2021-07-17T09:07:22.29366Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc3af1c6220c49ecb59b2dfa5d79f25e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "355/355 [==============================] - 7s 6ms/step - loss: 0.4096 - val_loss: 0.0940\n",
      "Epoch 2/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0775 - val_loss: 0.0911\n",
      "Epoch 3/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0701 - val_loss: 0.0888\n",
      "Epoch 4/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0668 - val_loss: 0.0957\n",
      "Epoch 5/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0656 - val_loss: 0.0850\n",
      "Epoch 6/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0612 - val_loss: 0.0784\n",
      "Epoch 7/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0624 - val_loss: 0.1006\n",
      "Epoch 8/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0599 - val_loss: 0.1056\n",
      "Epoch 9/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0572 - val_loss: 0.1165\n",
      "Epoch 10/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0557 - val_loss: 0.0820\n",
      "Epoch 11/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0567 - val_loss: 0.0921\n",
      "Epoch 12/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0544 - val_loss: 0.0943\n",
      "Epoch 13/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0542 - val_loss: 0.0939\n",
      "Epoch 14/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0539 - val_loss: 0.0953\n",
      "Epoch 15/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0523 - val_loss: 0.0967\n",
      "Epoch 16/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0511 - val_loss: 0.1082\n",
      "Epoch 1/100\n",
      "355/355 [==============================] - 5s 6ms/step - loss: 0.0659 - val_loss: 0.0818\n",
      "Epoch 2/100\n",
      "355/355 [==============================] - 1s 2ms/step - loss: 0.0621 - val_loss: 0.0820\n",
      "Epoch 3/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0601 - val_loss: 0.0887\n",
      "Epoch 4/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0577 - val_loss: 0.0813\n",
      "Epoch 5/100\n",
      "355/355 [==============================] - 1s 2ms/step - loss: 0.0550 - val_loss: 0.0896\n",
      "Epoch 6/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0545 - val_loss: 0.0960\n",
      "Epoch 7/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0537 - val_loss: 0.0782\n",
      "Epoch 8/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0534 - val_loss: 0.0990\n",
      "Epoch 9/100\n",
      "355/355 [==============================] - 1s 2ms/step - loss: 0.0526 - val_loss: 0.0919\n",
      "Epoch 10/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0507 - val_loss: 0.0924\n",
      "Epoch 11/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0495 - val_loss: 0.1025\n",
      "Epoch 12/100\n",
      "355/355 [==============================] - 1s 2ms/step - loss: 0.0499 - val_loss: 0.0833\n",
      "Epoch 13/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0487 - val_loss: 0.0884\n",
      "Epoch 14/100\n",
      "355/355 [==============================] - 1s 2ms/step - loss: 0.0486 - val_loss: 0.0907\n",
      "Epoch 15/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0464 - val_loss: 0.0891\n",
      "Epoch 16/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0466 - val_loss: 0.0941\n",
      "Epoch 17/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0481 - val_loss: 0.0858\n",
      "Epoch 1/100\n",
      "355/355 [==============================] - 5s 6ms/step - loss: 0.0587 - val_loss: 0.0854\n",
      "Epoch 2/100\n",
      "355/355 [==============================] - 1s 2ms/step - loss: 0.0572 - val_loss: 0.0713\n",
      "Epoch 3/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0548 - val_loss: 0.0831\n",
      "Epoch 4/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0536 - val_loss: 0.0975\n",
      "Epoch 5/100\n",
      "355/355 [==============================] - 1s 2ms/step - loss: 0.0523 - val_loss: 0.0819\n",
      "Epoch 6/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0498 - val_loss: 0.0730\n",
      "Epoch 7/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0496 - val_loss: 0.0969\n",
      "Epoch 8/100\n",
      "355/355 [==============================] - 1s 2ms/step - loss: 0.0504 - val_loss: 0.0890\n",
      "Epoch 9/100\n",
      "355/355 [==============================] - 1s 2ms/step - loss: 0.0486 - val_loss: 0.0980\n",
      "Epoch 10/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0485 - val_loss: 0.0908\n",
      "Epoch 11/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0455 - val_loss: 0.0927\n",
      "Epoch 12/100\n",
      "355/355 [==============================] - 1s 2ms/step - loss: 0.0454 - val_loss: 0.0784\n",
      "Epoch 1/100\n",
      "355/355 [==============================] - 5s 6ms/step - loss: 0.0582 - val_loss: 0.0919\n",
      "Epoch 2/100\n",
      "355/355 [==============================] - 1s 2ms/step - loss: 0.0543 - val_loss: 0.0755\n",
      "Epoch 3/100\n",
      "355/355 [==============================] - 1s 2ms/step - loss: 0.0523 - val_loss: 0.0831\n",
      "Epoch 4/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0525 - val_loss: 0.0926\n",
      "Epoch 5/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0513 - val_loss: 0.0946\n",
      "Epoch 6/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0488 - val_loss: 0.0838\n",
      "Epoch 7/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0490 - val_loss: 0.1046\n",
      "Epoch 8/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0491 - val_loss: 0.0864\n",
      "Epoch 9/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0467 - val_loss: 0.0947\n",
      "Epoch 10/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0460 - val_loss: 0.0880\n",
      "Epoch 11/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0454 - val_loss: 0.0850\n",
      "Epoch 12/100\n",
      "355/355 [==============================] - 1s 2ms/step - loss: 0.0445 - val_loss: 0.0876\n",
      "Epoch 1/100\n",
      "355/355 [==============================] - 5s 6ms/step - loss: 0.0563 - val_loss: 0.0727\n",
      "Epoch 2/100\n",
      "355/355 [==============================] - 1s 2ms/step - loss: 0.0527 - val_loss: 0.0909\n",
      "Epoch 3/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0522 - val_loss: 0.0756\n",
      "Epoch 4/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0507 - val_loss: 0.0892\n",
      "Epoch 5/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0495 - val_loss: 0.0910\n",
      "Epoch 6/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0500 - val_loss: 0.0807\n",
      "Epoch 7/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0478 - val_loss: 0.0788\n",
      "Epoch 8/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0459 - val_loss: 0.0836\n",
      "Epoch 9/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0477 - val_loss: 0.0827\n",
      "Epoch 10/100\n",
      "355/355 [==============================] - 1s 2ms/step - loss: 0.0460 - val_loss: 0.0835\n",
      "Epoch 11/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0439 - val_loss: 0.0755\n",
      "Epoch 1/100\n",
      "355/355 [==============================] - 5s 6ms/step - loss: 0.0553 - val_loss: 0.0790\n",
      "Epoch 2/100\n",
      "355/355 [==============================] - 1s 2ms/step - loss: 0.0545 - val_loss: 0.0897\n",
      "Epoch 3/100\n",
      "355/355 [==============================] - 1s 2ms/step - loss: 0.0508 - val_loss: 0.0780\n",
      "Epoch 4/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0497 - val_loss: 0.0760\n",
      "Epoch 5/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0494 - val_loss: 0.0857\n",
      "Epoch 6/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0493 - val_loss: 0.0811\n",
      "Epoch 7/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0475 - val_loss: 0.0943\n",
      "Epoch 8/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0445 - val_loss: 0.0998\n",
      "Epoch 9/100\n",
      "355/355 [==============================] - 1s 2ms/step - loss: 0.0456 - val_loss: 0.0809\n",
      "Epoch 10/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0440 - val_loss: 0.0889\n",
      "Epoch 11/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0438 - val_loss: 0.0806\n",
      "Epoch 12/100\n",
      "355/355 [==============================] - 1s 2ms/step - loss: 0.0438 - val_loss: 0.0916\n",
      "Epoch 13/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0433 - val_loss: 0.0847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0424 - val_loss: 0.0853\n",
      "Epoch 1/100\n",
      "355/355 [==============================] - 5s 6ms/step - loss: 0.0525 - val_loss: 0.0752\n",
      "Epoch 2/100\n",
      "355/355 [==============================] - 1s 2ms/step - loss: 0.0502 - val_loss: 0.0785\n",
      "Epoch 3/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0500 - val_loss: 0.0830\n",
      "Epoch 4/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0504 - val_loss: 0.0808\n",
      "Epoch 5/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0481 - val_loss: 0.0749\n",
      "Epoch 6/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0464 - val_loss: 0.0999\n",
      "Epoch 7/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0447 - val_loss: 0.0858\n",
      "Epoch 8/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0451 - val_loss: 0.0826\n",
      "Epoch 9/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0447 - val_loss: 0.0780\n",
      "Epoch 10/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0418 - val_loss: 0.0859\n",
      "Epoch 11/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0413 - val_loss: 0.0875\n",
      "Epoch 1/100\n",
      "355/355 [==============================] - 5s 6ms/step - loss: 0.0528 - val_loss: 0.0879\n",
      "Epoch 2/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0504 - val_loss: 0.0944\n",
      "Epoch 3/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0505 - val_loss: 0.0791\n",
      "Epoch 4/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0472 - val_loss: 0.0877\n",
      "Epoch 5/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0457 - val_loss: 0.0786\n",
      "Epoch 6/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0457 - val_loss: 0.0873\n",
      "Epoch 7/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0444 - val_loss: 0.0815\n",
      "Epoch 8/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0431 - val_loss: 0.0873\n",
      "Epoch 9/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0428 - val_loss: 0.0786\n",
      "Epoch 10/100\n",
      "355/355 [==============================] - 1s 2ms/step - loss: 0.0419 - val_loss: 0.0862\n",
      "Epoch 11/100\n",
      "355/355 [==============================] - 1s 2ms/step - loss: 0.0413 - val_loss: 0.0815\n",
      "Epoch 12/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0396 - val_loss: 0.0851\n",
      "Epoch 13/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0400 - val_loss: 0.0817\n",
      "Epoch 1/100\n",
      "355/355 [==============================] - 5s 6ms/step - loss: 0.0514 - val_loss: 0.0780\n",
      "Epoch 2/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0474 - val_loss: 0.0707\n",
      "Epoch 3/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0462 - val_loss: 0.0954\n",
      "Epoch 4/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0474 - val_loss: 0.0889\n",
      "Epoch 5/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0436 - val_loss: 0.0914\n",
      "Epoch 6/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0430 - val_loss: 0.0785\n",
      "Epoch 7/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0426 - val_loss: 0.0912\n",
      "Epoch 8/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0417 - val_loss: 0.0986\n",
      "Epoch 9/100\n",
      "355/355 [==============================] - 1s 2ms/step - loss: 0.0429 - val_loss: 0.0943\n",
      "Epoch 10/100\n",
      "355/355 [==============================] - 1s 2ms/step - loss: 0.0406 - val_loss: 0.0799\n",
      "Epoch 11/100\n",
      "355/355 [==============================] - 1s 2ms/step - loss: 0.0392 - val_loss: 0.0830\n",
      "Epoch 12/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0390 - val_loss: 0.0835\n",
      "Epoch 1/100\n",
      "355/355 [==============================] - 5s 6ms/step - loss: 0.0485 - val_loss: 0.0759\n",
      "Epoch 2/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0474 - val_loss: 0.0787\n",
      "Epoch 3/100\n",
      "355/355 [==============================] - 1s 2ms/step - loss: 0.0471 - val_loss: 0.0731\n",
      "Epoch 4/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0473 - val_loss: 0.0819\n",
      "Epoch 5/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0445 - val_loss: 0.0902\n",
      "Epoch 6/100\n",
      "355/355 [==============================] - 1s 2ms/step - loss: 0.0446 - val_loss: 0.0889\n",
      "Epoch 7/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0416 - val_loss: 0.0803\n",
      "Epoch 8/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0407 - val_loss: 0.0899\n",
      "Epoch 9/100\n",
      "355/355 [==============================] - 1s 2ms/step - loss: 0.0412 - val_loss: 0.0802\n",
      "Epoch 10/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0394 - val_loss: 0.0948\n",
      "Epoch 11/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0390 - val_loss: 0.0838\n",
      "Epoch 12/100\n",
      "355/355 [==============================] - 1s 2ms/step - loss: 0.0386 - val_loss: 0.0902\n",
      "Epoch 13/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0383 - val_loss: 0.0825\n",
      "Epoch 1/100\n",
      "355/355 [==============================] - 5s 6ms/step - loss: 0.0471 - val_loss: 0.0715\n",
      "Epoch 2/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0467 - val_loss: 0.0813\n",
      "Epoch 3/100\n",
      "355/355 [==============================] - 1s 2ms/step - loss: 0.0448 - val_loss: 0.0820\n",
      "Epoch 4/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0428 - val_loss: 0.0941\n",
      "Epoch 5/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0432 - val_loss: 0.0799\n",
      "Epoch 6/100\n",
      "355/355 [==============================] - 1s 2ms/step - loss: 0.0415 - val_loss: 0.0832\n",
      "Epoch 7/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0424 - val_loss: 0.0828\n",
      "Epoch 8/100\n",
      "355/355 [==============================] - 1s 2ms/step - loss: 0.0405 - val_loss: 0.0793\n",
      "Epoch 9/100\n",
      "355/355 [==============================] - 1s 2ms/step - loss: 0.0380 - val_loss: 0.0834\n",
      "Epoch 10/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0380 - val_loss: 0.0923\n",
      "Epoch 11/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0373 - val_loss: 0.0873\n",
      "Epoch 1/100\n",
      "355/355 [==============================] - 5s 6ms/step - loss: 0.0486 - val_loss: 0.0817\n",
      "Epoch 2/100\n",
      "355/355 [==============================] - 1s 2ms/step - loss: 0.0464 - val_loss: 0.0806\n",
      "Epoch 3/100\n",
      "355/355 [==============================] - 1s 2ms/step - loss: 0.0454 - val_loss: 0.0815\n",
      "Epoch 4/100\n",
      "355/355 [==============================] - 1s 2ms/step - loss: 0.0433 - val_loss: 0.0803\n",
      "Epoch 5/100\n",
      "355/355 [==============================] - 1s 2ms/step - loss: 0.0430 - val_loss: 0.0808\n",
      "Epoch 6/100\n",
      "355/355 [==============================] - 1s 2ms/step - loss: 0.0420 - val_loss: 0.0838\n",
      "Epoch 7/100\n",
      "355/355 [==============================] - 1s 2ms/step - loss: 0.0408 - val_loss: 0.0833\n",
      "Epoch 8/100\n",
      "355/355 [==============================] - 1s 2ms/step - loss: 0.0392 - val_loss: 0.0807\n",
      "Epoch 9/100\n",
      "355/355 [==============================] - 1s 2ms/step - loss: 0.0403 - val_loss: 0.0786\n",
      "Epoch 10/100\n",
      "355/355 [==============================] - 1s 2ms/step - loss: 0.0387 - val_loss: 0.0888\n",
      "Epoch 11/100\n",
      "355/355 [==============================] - 1s 2ms/step - loss: 0.0367 - val_loss: 0.0816\n",
      "Epoch 12/100\n",
      "355/355 [==============================] - 1s 2ms/step - loss: 0.0370 - val_loss: 0.0904\n",
      "Epoch 13/100\n",
      "355/355 [==============================] - 1s 2ms/step - loss: 0.0360 - val_loss: 0.0802\n",
      "Epoch 14/100\n",
      "355/355 [==============================] - 1s 2ms/step - loss: 0.0342 - val_loss: 0.0862\n",
      "Epoch 15/100\n",
      "355/355 [==============================] - 1s 2ms/step - loss: 0.0352 - val_loss: 0.0847\n",
      "Epoch 16/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0340 - val_loss: 0.0876\n",
      "Epoch 17/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0360 - val_loss: 0.0886\n",
      "Epoch 18/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0328 - val_loss: 0.0835\n",
      "Epoch 19/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0340 - val_loss: 0.0892\n",
      "Epoch 1/100\n",
      "355/355 [==============================] - 5s 6ms/step - loss: 0.0444 - val_loss: 0.0797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0427 - val_loss: 0.0769\n",
      "Epoch 3/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0411 - val_loss: 0.0772\n",
      "Epoch 4/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0406 - val_loss: 0.0789\n",
      "Epoch 5/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0396 - val_loss: 0.0838\n",
      "Epoch 6/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0377 - val_loss: 0.0851\n",
      "Epoch 7/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0368 - val_loss: 0.0927\n",
      "Epoch 8/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0360 - val_loss: 0.0935\n",
      "Epoch 9/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0346 - val_loss: 0.0855\n",
      "Epoch 10/100\n",
      "355/355 [==============================] - 1s 2ms/step - loss: 0.0339 - val_loss: 0.0851\n",
      "Epoch 11/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0340 - val_loss: 0.0863\n",
      "Epoch 12/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0335 - val_loss: 0.0847\n",
      "Epoch 1/100\n",
      "355/355 [==============================] - 5s 6ms/step - loss: 0.0454 - val_loss: 0.0923\n",
      "Epoch 2/100\n",
      "355/355 [==============================] - 1s 2ms/step - loss: 0.0413 - val_loss: 0.0768\n",
      "Epoch 3/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0401 - val_loss: 0.0725\n",
      "Epoch 4/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0394 - val_loss: 0.0964\n",
      "Epoch 5/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0379 - val_loss: 0.0816\n",
      "Epoch 6/100\n",
      "355/355 [==============================] - 1s 2ms/step - loss: 0.0363 - val_loss: 0.0810\n",
      "Epoch 7/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0367 - val_loss: 0.0892\n",
      "Epoch 8/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0357 - val_loss: 0.0913\n",
      "Epoch 9/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0336 - val_loss: 0.0856\n",
      "Epoch 10/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0329 - val_loss: 0.0906\n",
      "Epoch 11/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0332 - val_loss: 0.0856\n",
      "Epoch 12/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0323 - val_loss: 0.0791\n",
      "Epoch 13/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0314 - val_loss: 0.0861\n",
      "Epoch 1/100\n",
      "355/355 [==============================] - 5s 6ms/step - loss: 0.0418 - val_loss: 0.0742\n",
      "Epoch 2/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0407 - val_loss: 0.0769\n",
      "Epoch 3/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0402 - val_loss: 0.0795\n",
      "Epoch 4/100\n",
      "355/355 [==============================] - 1s 2ms/step - loss: 0.0375 - val_loss: 0.0781\n",
      "Epoch 5/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0381 - val_loss: 0.0873\n",
      "Epoch 6/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0368 - val_loss: 0.0834\n",
      "Epoch 7/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0353 - val_loss: 0.0843\n",
      "Epoch 8/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0343 - val_loss: 0.0846\n",
      "Epoch 9/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0343 - val_loss: 0.0826\n",
      "Epoch 10/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0338 - val_loss: 0.0837\n",
      "Epoch 11/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0317 - val_loss: 0.0856\n",
      "Epoch 1/100\n",
      "355/355 [==============================] - 5s 6ms/step - loss: 0.0423 - val_loss: 0.0940\n",
      "Epoch 2/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0402 - val_loss: 0.0752\n",
      "Epoch 3/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0394 - val_loss: 0.0772\n",
      "Epoch 4/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0382 - val_loss: 0.0833\n",
      "Epoch 5/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0369 - val_loss: 0.0785\n",
      "Epoch 6/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0372 - val_loss: 0.0847\n",
      "Epoch 7/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0349 - val_loss: 0.0873\n",
      "Epoch 8/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0334 - val_loss: 0.0882\n",
      "Epoch 9/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0335 - val_loss: 0.0883\n",
      "Epoch 10/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0334 - val_loss: 0.0839\n",
      "Epoch 11/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0319 - val_loss: 0.0910\n",
      "Epoch 12/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0305 - val_loss: 0.0876\n",
      "Epoch 1/100\n",
      "355/355 [==============================] - 7s 12ms/step - loss: 0.0408 - val_loss: 0.0909\n",
      "Epoch 2/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0394 - val_loss: 0.0916\n",
      "Epoch 3/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0401 - val_loss: 0.0930\n",
      "Epoch 4/100\n",
      "355/355 [==============================] - 1s 2ms/step - loss: 0.0382 - val_loss: 0.0829\n",
      "Epoch 5/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0359 - val_loss: 0.0919\n",
      "Epoch 6/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0353 - val_loss: 0.0832\n",
      "Epoch 7/100\n",
      "355/355 [==============================] - 1s 2ms/step - loss: 0.0347 - val_loss: 0.0900\n",
      "Epoch 8/100\n",
      "355/355 [==============================] - 1s 2ms/step - loss: 0.0336 - val_loss: 0.0782\n",
      "Epoch 9/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0321 - val_loss: 0.0844\n",
      "Epoch 10/100\n",
      "355/355 [==============================] - 1s 2ms/step - loss: 0.0310 - val_loss: 0.0912\n",
      "Epoch 11/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0305 - val_loss: 0.0900\n",
      "Epoch 12/100\n",
      "355/355 [==============================] - 1s 2ms/step - loss: 0.0305 - val_loss: 0.0870\n",
      "Epoch 13/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0295 - val_loss: 0.0899\n",
      "Epoch 14/100\n",
      "355/355 [==============================] - 1s 2ms/step - loss: 0.0290 - val_loss: 0.0868\n",
      "Epoch 15/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0288 - val_loss: 0.0859\n",
      "Epoch 16/100\n",
      "355/355 [==============================] - 1s 2ms/step - loss: 0.0277 - val_loss: 0.0863\n",
      "Epoch 17/100\n",
      "355/355 [==============================] - 1s 2ms/step - loss: 0.0281 - val_loss: 0.0884\n",
      "Epoch 18/100\n",
      "355/355 [==============================] - 1s 2ms/step - loss: 0.0264 - val_loss: 0.0889\n",
      "Epoch 1/100\n",
      "355/355 [==============================] - 5s 5ms/step - loss: 0.0387 - val_loss: 0.0899\n",
      "Epoch 2/100\n",
      "355/355 [==============================] - 1s 2ms/step - loss: 0.0370 - val_loss: 0.0848\n",
      "Epoch 3/100\n",
      "355/355 [==============================] - 1s 2ms/step - loss: 0.0346 - val_loss: 0.0967\n",
      "Epoch 4/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0340 - val_loss: 0.0978\n",
      "Epoch 5/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0360 - val_loss: 0.0839\n",
      "Epoch 6/100\n",
      "355/355 [==============================] - 1s 2ms/step - loss: 0.0324 - val_loss: 0.0958\n",
      "Epoch 7/100\n",
      "355/355 [==============================] - 1s 2ms/step - loss: 0.0319 - val_loss: 0.0807\n",
      "Epoch 8/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0303 - val_loss: 0.0876\n",
      "Epoch 9/100\n",
      "355/355 [==============================] - 1s 2ms/step - loss: 0.0297 - val_loss: 0.0903\n",
      "Epoch 10/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0289 - val_loss: 0.0883\n",
      "Epoch 11/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0286 - val_loss: 0.0869\n",
      "Epoch 12/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0273 - val_loss: 0.0858\n",
      "Epoch 13/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0277 - val_loss: 0.0841\n",
      "Epoch 14/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0270 - val_loss: 0.0908\n",
      "Epoch 15/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0270 - val_loss: 0.0872\n",
      "Epoch 16/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0263 - val_loss: 0.0871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0249 - val_loss: 0.0870\n",
      "Epoch 1/100\n",
      "355/355 [==============================] - 6s 7ms/step - loss: 0.0372 - val_loss: 0.0832\n",
      "Epoch 2/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0359 - val_loss: 0.0787\n",
      "Epoch 3/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0343 - val_loss: 0.0917\n",
      "Epoch 4/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0336 - val_loss: 0.0863\n",
      "Epoch 5/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0329 - val_loss: 0.0873\n",
      "Epoch 6/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0311 - val_loss: 0.0840\n",
      "Epoch 7/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0298 - val_loss: 0.0839\n",
      "Epoch 8/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0293 - val_loss: 0.0822\n",
      "Epoch 9/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0278 - val_loss: 0.0813\n",
      "Epoch 10/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0268 - val_loss: 0.0885\n",
      "Epoch 11/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0267 - val_loss: 0.0827\n",
      "Epoch 12/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0258 - val_loss: 0.0866\n",
      "Epoch 1/100\n",
      "355/355 [==============================] - 6s 7ms/step - loss: 0.0365 - val_loss: 0.0831\n",
      "Epoch 2/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0346 - val_loss: 0.0845\n",
      "Epoch 3/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0345 - val_loss: 0.0904\n",
      "Epoch 4/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0331 - val_loss: 0.0809\n",
      "Epoch 5/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0317 - val_loss: 0.0838\n",
      "Epoch 6/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0307 - val_loss: 0.0834\n",
      "Epoch 7/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0298 - val_loss: 0.0871\n",
      "Epoch 8/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0285 - val_loss: 0.0863\n",
      "Epoch 9/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0281 - val_loss: 0.0862\n",
      "Epoch 10/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0267 - val_loss: 0.0861\n",
      "Epoch 11/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0266 - val_loss: 0.0881\n",
      "Epoch 12/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0250 - val_loss: 0.0845\n",
      "Epoch 13/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0250 - val_loss: 0.0883\n",
      "Epoch 14/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.0249 - val_loss: 0.0901\n"
     ]
    }
   ],
   "source": [
    "N_SAMPLE = 20\n",
    "yhat_tno = np.zeros((Xtest_sub.shape[0],1))\n",
    "\n",
    "for samples in tqdm(range(N_SAMPLE)):\n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    model_tno.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.02), loss= rmsle)\n",
    "    history_tno = model_tno.fit(Xtrain_seq_tno, ytrain_seq_tno, \n",
    "                            validation_data = (Xtest_seq_tno, ytest_seq_tno), \n",
    "                            epochs=100, \n",
    "                            verbose = 1, \n",
    "                            batch_size = 16, \n",
    "                            callbacks=[es, red_lr])\n",
    "    \n",
    "  \n",
    "    yhat_tno += np.expm1(model_tno.predict(Xtest_sub)).reshape(-1,1)\n",
    "\n",
    "yhat_tno = yhat_tno / N_SAMPLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-17T09:12:25.471056Z",
     "iopub.status.busy": "2021-07-17T09:12:25.470746Z",
     "iopub.status.idle": "2021-07-17T09:12:25.496134Z",
     "shell.execute_reply": "2021-07-17T09:12:25.495133Z",
     "shell.execute_reply.started": "2021-07-17T09:12:25.471026Z"
    }
   },
   "outputs": [],
   "source": [
    "# Submission\n",
    "df_sub['target_carbon_monoxide'] =  yhat_tcm\n",
    "df_sub['target_benzene'] = yhat_tb\n",
    "df_sub['target_nitrogen_oxides'] = yhat_tno\n",
    "\n",
    "df_sub.to_csv('lstm_001.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-17T09:12:25.499432Z",
     "iopub.status.busy": "2021-07-17T09:12:25.499171Z",
     "iopub.status.idle": "2021-07-17T09:12:25.519504Z",
     "shell.execute_reply": "2021-07-17T09:12:25.518471Z",
     "shell.execute_reply.started": "2021-07-17T09:12:25.499405Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_time</th>\n",
       "      <th>target_carbon_monoxide</th>\n",
       "      <th>target_benzene</th>\n",
       "      <th>target_nitrogen_oxides</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-01 00:00:00</td>\n",
       "      <td>1.506565</td>\n",
       "      <td>4.910899</td>\n",
       "      <td>302.449928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-01 01:00:00</td>\n",
       "      <td>1.673048</td>\n",
       "      <td>5.506151</td>\n",
       "      <td>269.728941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-01 02:00:00</td>\n",
       "      <td>2.365980</td>\n",
       "      <td>8.217354</td>\n",
       "      <td>351.887906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-01 03:00:00</td>\n",
       "      <td>2.201139</td>\n",
       "      <td>8.506038</td>\n",
       "      <td>300.537603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-01 04:00:00</td>\n",
       "      <td>2.331467</td>\n",
       "      <td>8.790062</td>\n",
       "      <td>266.922013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2242</th>\n",
       "      <td>2011-04-04 10:00:00</td>\n",
       "      <td>2.356931</td>\n",
       "      <td>11.094714</td>\n",
       "      <td>220.149908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2243</th>\n",
       "      <td>2011-04-04 11:00:00</td>\n",
       "      <td>2.519680</td>\n",
       "      <td>11.416447</td>\n",
       "      <td>187.439294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2244</th>\n",
       "      <td>2011-04-04 12:00:00</td>\n",
       "      <td>2.321282</td>\n",
       "      <td>11.059037</td>\n",
       "      <td>169.660686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2245</th>\n",
       "      <td>2011-04-04 13:00:00</td>\n",
       "      <td>2.447847</td>\n",
       "      <td>11.228000</td>\n",
       "      <td>147.657148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2246</th>\n",
       "      <td>2011-04-04 14:00:00</td>\n",
       "      <td>2.025696</td>\n",
       "      <td>8.214611</td>\n",
       "      <td>149.521081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2247 rows Ã 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                date_time  target_carbon_monoxide  target_benzene  \\\n",
       "0     2011-01-01 00:00:00                1.506565        4.910899   \n",
       "1     2011-01-01 01:00:00                1.673048        5.506151   \n",
       "2     2011-01-01 02:00:00                2.365980        8.217354   \n",
       "3     2011-01-01 03:00:00                2.201139        8.506038   \n",
       "4     2011-01-01 04:00:00                2.331467        8.790062   \n",
       "...                   ...                     ...             ...   \n",
       "2242  2011-04-04 10:00:00                2.356931       11.094714   \n",
       "2243  2011-04-04 11:00:00                2.519680       11.416447   \n",
       "2244  2011-04-04 12:00:00                2.321282       11.059037   \n",
       "2245  2011-04-04 13:00:00                2.447847       11.228000   \n",
       "2246  2011-04-04 14:00:00                2.025696        8.214611   \n",
       "\n",
       "      target_nitrogen_oxides  \n",
       "0                 302.449928  \n",
       "1                 269.728941  \n",
       "2                 351.887906  \n",
       "3                 300.537603  \n",
       "4                 266.922013  \n",
       "...                      ...  \n",
       "2242              220.149908  \n",
       "2243              187.439294  \n",
       "2244              169.660686  \n",
       "2245              147.657148  \n",
       "2246              149.521081  \n",
       "\n",
       "[2247 rows x 4 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
