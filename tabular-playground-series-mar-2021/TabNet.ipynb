{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "import torch\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import plotly.express as px\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./data/train.csv')\n",
    "test_df = pd.read_csv('./data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAT_COLS = [c for c in train_df.columns if c.startswith(\"cat\")]\n",
    "NUM_COLS = [c for c in train_df.columns if c.startswith(\"cont\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOW_FREQ_THRESH = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cat0</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>...</th>\n",
       "      <th>cont2</th>\n",
       "      <th>cont3</th>\n",
       "      <th>cont4</th>\n",
       "      <th>cont5</th>\n",
       "      <th>cont6</th>\n",
       "      <th>cont7</th>\n",
       "      <th>cont8</th>\n",
       "      <th>cont9</th>\n",
       "      <th>cont10</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>I</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>BI</td>\n",
       "      <td>A</td>\n",
       "      <td>S</td>\n",
       "      <td>Q</td>\n",
       "      <td>...</td>\n",
       "      <td>0.759439</td>\n",
       "      <td>0.795549</td>\n",
       "      <td>0.681917</td>\n",
       "      <td>0.621672</td>\n",
       "      <td>0.592184</td>\n",
       "      <td>0.791921</td>\n",
       "      <td>0.815254</td>\n",
       "      <td>0.965006</td>\n",
       "      <td>0.665915</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>I</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>BI</td>\n",
       "      <td>K</td>\n",
       "      <td>W</td>\n",
       "      <td>AD</td>\n",
       "      <td>...</td>\n",
       "      <td>0.386385</td>\n",
       "      <td>0.541366</td>\n",
       "      <td>0.388982</td>\n",
       "      <td>0.357778</td>\n",
       "      <td>0.600044</td>\n",
       "      <td>0.408701</td>\n",
       "      <td>0.399353</td>\n",
       "      <td>0.927406</td>\n",
       "      <td>0.493729</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>K</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>BI</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>BM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.343255</td>\n",
       "      <td>0.616352</td>\n",
       "      <td>0.793687</td>\n",
       "      <td>0.552877</td>\n",
       "      <td>0.352113</td>\n",
       "      <td>0.388835</td>\n",
       "      <td>0.412303</td>\n",
       "      <td>0.292696</td>\n",
       "      <td>0.549452</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>A</td>\n",
       "      <td>K</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>E</td>\n",
       "      <td>BI</td>\n",
       "      <td>A</td>\n",
       "      <td>Y</td>\n",
       "      <td>AD</td>\n",
       "      <td>...</td>\n",
       "      <td>0.831147</td>\n",
       "      <td>0.807807</td>\n",
       "      <td>0.800032</td>\n",
       "      <td>0.619147</td>\n",
       "      <td>0.221789</td>\n",
       "      <td>0.897617</td>\n",
       "      <td>0.633669</td>\n",
       "      <td>0.760318</td>\n",
       "      <td>0.934242</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>A</td>\n",
       "      <td>I</td>\n",
       "      <td>G</td>\n",
       "      <td>B</td>\n",
       "      <td>E</td>\n",
       "      <td>BI</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>Q</td>\n",
       "      <td>...</td>\n",
       "      <td>0.338818</td>\n",
       "      <td>0.277308</td>\n",
       "      <td>0.610578</td>\n",
       "      <td>0.128291</td>\n",
       "      <td>0.578764</td>\n",
       "      <td>0.279167</td>\n",
       "      <td>0.351103</td>\n",
       "      <td>0.357084</td>\n",
       "      <td>0.328960</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299995</th>\n",
       "      <td>499993</td>\n",
       "      <td>A</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>BU</td>\n",
       "      <td>A</td>\n",
       "      <td>AS</td>\n",
       "      <td>K</td>\n",
       "      <td>...</td>\n",
       "      <td>0.662428</td>\n",
       "      <td>0.671927</td>\n",
       "      <td>0.390566</td>\n",
       "      <td>0.145840</td>\n",
       "      <td>0.262767</td>\n",
       "      <td>0.514248</td>\n",
       "      <td>0.519340</td>\n",
       "      <td>0.617436</td>\n",
       "      <td>0.688007</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299996</th>\n",
       "      <td>499995</td>\n",
       "      <td>A</td>\n",
       "      <td>K</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>BI</td>\n",
       "      <td>A</td>\n",
       "      <td>K</td>\n",
       "      <td>AE</td>\n",
       "      <td>...</td>\n",
       "      <td>0.821657</td>\n",
       "      <td>0.620356</td>\n",
       "      <td>0.384891</td>\n",
       "      <td>0.735879</td>\n",
       "      <td>0.547731</td>\n",
       "      <td>0.726653</td>\n",
       "      <td>0.470575</td>\n",
       "      <td>0.275743</td>\n",
       "      <td>0.638939</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299997</th>\n",
       "      <td>499996</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>M</td>\n",
       "      <td>A</td>\n",
       "      <td>H</td>\n",
       "      <td>BI</td>\n",
       "      <td>C</td>\n",
       "      <td>L</td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>0.407037</td>\n",
       "      <td>0.232436</td>\n",
       "      <td>0.832482</td>\n",
       "      <td>0.810663</td>\n",
       "      <td>0.596939</td>\n",
       "      <td>0.308821</td>\n",
       "      <td>0.373997</td>\n",
       "      <td>0.518024</td>\n",
       "      <td>0.452144</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299998</th>\n",
       "      <td>499997</td>\n",
       "      <td>B</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>BI</td>\n",
       "      <td>A</td>\n",
       "      <td>AA</td>\n",
       "      <td>AX</td>\n",
       "      <td>...</td>\n",
       "      <td>0.808045</td>\n",
       "      <td>0.630708</td>\n",
       "      <td>0.346898</td>\n",
       "      <td>0.735147</td>\n",
       "      <td>0.563488</td>\n",
       "      <td>0.609836</td>\n",
       "      <td>0.680430</td>\n",
       "      <td>0.318453</td>\n",
       "      <td>0.335822</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299999</th>\n",
       "      <td>499999</td>\n",
       "      <td>A</td>\n",
       "      <td>F</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>BI</td>\n",
       "      <td>C</td>\n",
       "      <td>AV</td>\n",
       "      <td>S</td>\n",
       "      <td>...</td>\n",
       "      <td>0.775451</td>\n",
       "      <td>0.848696</td>\n",
       "      <td>0.819377</td>\n",
       "      <td>0.355467</td>\n",
       "      <td>0.218153</td>\n",
       "      <td>0.968856</td>\n",
       "      <td>0.823655</td>\n",
       "      <td>0.330515</td>\n",
       "      <td>0.972569</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300000 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id cat0 cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8  ...     cont2  \\\n",
       "0            0    A    I    A    B    B   BI    A    S    Q  ...  0.759439   \n",
       "1            1    A    I    A    A    E   BI    K    W   AD  ...  0.386385   \n",
       "2            2    A    K    A    A    E   BI    A    E   BM  ...  0.343255   \n",
       "3            3    A    K    A    C    E   BI    A    Y   AD  ...  0.831147   \n",
       "4            4    A    I    G    B    E   BI    C    G    Q  ...  0.338818   \n",
       "...        ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...       ...   \n",
       "299995  499993    A    N    F    A    E   BU    A   AS    K  ...  0.662428   \n",
       "299996  499995    A    K    A    A    G   BI    A    K   AE  ...  0.821657   \n",
       "299997  499996    A    G    M    A    H   BI    C    L    F  ...  0.407037   \n",
       "299998  499997    B    H    A    D    B   BI    A   AA   AX  ...  0.808045   \n",
       "299999  499999    A    F    C    A    E   BI    C   AV    S  ...  0.775451   \n",
       "\n",
       "           cont3     cont4     cont5     cont6     cont7     cont8     cont9  \\\n",
       "0       0.795549  0.681917  0.621672  0.592184  0.791921  0.815254  0.965006   \n",
       "1       0.541366  0.388982  0.357778  0.600044  0.408701  0.399353  0.927406   \n",
       "2       0.616352  0.793687  0.552877  0.352113  0.388835  0.412303  0.292696   \n",
       "3       0.807807  0.800032  0.619147  0.221789  0.897617  0.633669  0.760318   \n",
       "4       0.277308  0.610578  0.128291  0.578764  0.279167  0.351103  0.357084   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "299995  0.671927  0.390566  0.145840  0.262767  0.514248  0.519340  0.617436   \n",
       "299996  0.620356  0.384891  0.735879  0.547731  0.726653  0.470575  0.275743   \n",
       "299997  0.232436  0.832482  0.810663  0.596939  0.308821  0.373997  0.518024   \n",
       "299998  0.630708  0.346898  0.735147  0.563488  0.609836  0.680430  0.318453   \n",
       "299999  0.848696  0.819377  0.355467  0.218153  0.968856  0.823655  0.330515   \n",
       "\n",
       "          cont10 target  \n",
       "0       0.665915      0  \n",
       "1       0.493729      0  \n",
       "2       0.549452      0  \n",
       "3       0.934242      0  \n",
       "4       0.328960      1  \n",
       "...          ...    ...  \n",
       "299995  0.688007      0  \n",
       "299996  0.638939      0  \n",
       "299997  0.452144      1  \n",
       "299998  0.335822      0  \n",
       "299999  0.972569      0  \n",
       "\n",
       "[300000 rows x 32 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoders = {}\n",
    "# for cat_col in CAT_COLS[0:2]:\n",
    "for cat_col in CAT_COLS:\n",
    "   #  print(\"=\" * 50)\n",
    "    label_enc = LabelEncoder()\n",
    "    \n",
    "    value_counts = train_df[cat_col].value_counts()\n",
    "    # print(value_counts)\n",
    "    # print(type(value_counts))\n",
    "    \n",
    "    is_low_frequency = value_counts < LOW_FREQ_THRESH\n",
    "    # print(\"-\" * 50)\n",
    "    # print(is_low_frequency)\n",
    "    # print(type(is_low_frequency))\n",
    "    \n",
    "    low_freq_values = value_counts.index[is_low_frequency]\n",
    "    \n",
    "    # print(\"-\" * 50)\n",
    "    # print(low_freq_values)\n",
    "    # print(type(low_freq_values))\n",
    "    \n",
    "    if len(low_freq_values) > 0:\n",
    "        train_df.loc[train_df[cat_col].isin(low_freq_values), cat_col] = \"low_frequency\"\n",
    "        test_df.loc[test_df[cat_col].isin(low_freq_values), cat_col] = \"low_frequency\"\n",
    "        \n",
    "    train_df[cat_col] = label_enc.fit_transform(train_df[cat_col])\n",
    "    encoders[cat_col] = label_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode test set\n",
    "for cat_col in CAT_COLS:\n",
    "    label_enc = encoders[cat_col]\n",
    "    le_dict = dict(zip(label_enc.classes_, label_enc.transform(label_enc.classes_)))\n",
    "    \n",
    "    # Replace unknown values by the most common value\n",
    "    # Changing this to another value might make more sense\n",
    "    if le_dict.get(\"low_frequency\") is not None:\n",
    "        default_val = le_dict[\"low_frequency\"]\n",
    "    else:\n",
    "        default_val = train_df[cat_col].mode().values[0]\n",
    "        \n",
    "    test_df[cat_col] = test_df[cat_col].apply(lambda x: le_dict.get(x, default_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clip numerical features in test set to match training set\n",
    "for num_col in NUM_COLS:\n",
    "    test_df[num_col] = np.clip(test_df[num_col], train_df[num_col].min(), train_df[num_col].max())\n",
    "    \n",
    "    # Taken from https://www.kaggle.com/siavrez/kerasembeddings\n",
    "    train_df[f'q_{num_col}'], bins_ = pd.qcut(train_df[num_col], 25, retbins=True, labels=[i for i in range(25)])\n",
    "    test_df[f'q_{num_col}'] = pd.cut(test_df[num_col], bins=bins_, labels=False, include_lowest=True)\n",
    "    CAT_COLS.append(f'q_{num_col}')\n",
    "\n",
    "FEATURES = CAT_COLS + NUM_COLS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_dims = train_df[CAT_COLS].nunique().to_list()\n",
    "cat_idxs = [FEATURES.index(cat_col) for cat_col in CAT_COLS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_emb_dims = np.ceil(np.log(cat_dims)).astype(np.int).tolist()\n",
    "cat_emb_dims = np.ceil(np.clip((np.array(cat_dims)) / 2, a_min=1, a_max=50)).astype(np.int).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df[FEATURES].values\n",
    "y = train_df[\"target\"].values\n",
    "\n",
    "X_test = test_df[FEATURES].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_tabnet.pretraining import TabNetPretrainer\n",
    "\n",
    "N_D = 16\n",
    "N_A = 16\n",
    "N_INDEP = 2\n",
    "N_SHARED = 2\n",
    "N_STEPS = 1 #2\n",
    "MASK_TYPE = \"sparsemax\"\n",
    "GAMMA = 1.5\n",
    "BS = 512\n",
    "MAX_EPOCH =  20 # 20\n",
    "PRETRAIN = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cpu\n",
      "epoch 0  | loss: 0.96492 | val_0_unsup_loss: 0.60902 |  0:00:52s\n",
      "epoch 1  | loss: 0.40539 | val_0_unsup_loss: 0.34515 |  0:01:44s\n",
      "epoch 2  | loss: 0.30284 | val_0_unsup_loss: 0.27205 |  0:02:32s\n",
      "epoch 3  | loss: 0.25778 | val_0_unsup_loss: 0.25856 |  0:03:21s\n",
      "epoch 4  | loss: 0.23388 | val_0_unsup_loss: 0.24927 |  0:04:10s\n",
      "epoch 5  | loss: 0.22158 | val_0_unsup_loss: 0.22673 |  0:04:57s\n",
      "epoch 6  | loss: 0.20809 | val_0_unsup_loss: 0.2244  |  0:05:45s\n",
      "epoch 7  | loss: 0.19475 | val_0_unsup_loss: 0.22669 |  0:06:32s\n",
      "epoch 8  | loss: 0.18764 | val_0_unsup_loss: 0.20731 |  0:07:20s\n",
      "epoch 9  | loss: 0.18412 | val_0_unsup_loss: 0.21684 |  0:08:07s\n",
      "epoch 10 | loss: 0.18259 | val_0_unsup_loss: 0.20244 |  0:08:55s\n",
      "epoch 11 | loss: 0.17736 | val_0_unsup_loss: 0.21646 |  0:09:42s\n",
      "epoch 12 | loss: 0.17506 | val_0_unsup_loss: 0.19888 |  0:10:30s\n",
      "epoch 13 | loss: 0.17098 | val_0_unsup_loss: 0.20125 |  0:11:19s\n",
      "epoch 14 | loss: 0.17226 | val_0_unsup_loss: 0.19586 |  0:12:06s\n",
      "epoch 15 | loss: 0.16859 | val_0_unsup_loss: 0.19757 |  0:12:53s\n",
      "epoch 16 | loss: 0.1696  | val_0_unsup_loss: 0.195   |  0:13:41s\n",
      "epoch 17 | loss: 0.16781 | val_0_unsup_loss: 0.20979 |  0:14:28s\n",
      "epoch 18 | loss: 0.16558 | val_0_unsup_loss: 0.20109 |  0:15:16s\n",
      "epoch 19 | loss: 0.16526 | val_0_unsup_loss: 0.19713 |  0:16:04s\n",
      "Stop training because you reached max_epochs = 20 with best_epoch = 16 and best_val_0_unsup_loss = 0.195\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    }
   ],
   "source": [
    "# https://www.guruguru.science/competitions/16/discussions/70f25f95-4dcc-4733-9f9e-f7bc6472d7c0/\n",
    "if PRETRAIN:\n",
    "    pretrain_params = dict(n_d=N_D, n_a=N_A, n_steps=N_STEPS,  #0.2,\n",
    "                           n_independent=N_INDEP, n_shared=N_SHARED,\n",
    "                           cat_idxs=cat_idxs,\n",
    "                           cat_dims=cat_dims,\n",
    "                           cat_emb_dim=cat_emb_dims,\n",
    "                           gamma=GAMMA,\n",
    "                           lambda_sparse=0., optimizer_fn=torch.optim.Adam,\n",
    "                           optimizer_params=dict(lr=2e-2),\n",
    "                           mask_type=MASK_TYPE,\n",
    "                           scheduler_params=dict(mode=\"min\",\n",
    "                                                 patience=3,\n",
    "                                                 min_lr=1e-5,\n",
    "                                                 factor=0.5,),\n",
    "                           scheduler_fn=torch.optim.lr_scheduler.ReduceLROnPlateau,                         \n",
    "                           verbose=1,\n",
    "                          )\n",
    "    pretrainer = TabNetPretrainer(**pretrain_params)\n",
    "\n",
    "    pretrainer.fit(X_train=X_test, \n",
    "                   eval_set=[X],\n",
    "                   max_epochs=MAX_EPOCH,\n",
    "                   patience=25, batch_size=BS, virtual_batch_size=BS, #128,\n",
    "                   num_workers=0, drop_last=True,\n",
    "                   pretraining_ratio=0.5 # The bigger your pretraining_ratio the harder it is to reconstruct\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
